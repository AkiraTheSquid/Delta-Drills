# Model configuration:
# - models: comma-separated list of models to use
# - model_cycle:
#     - "round_robin": cycle models per prompt (prompt 0 uses first, prompt 1 uses second, etc.)
#     - "fallback": always start with first model; try next models only on specific failures (e.g. RPD/429)
models="gpt-4o-mini,gpt-4.1-mini,gpt-4o"
model_cycle="round_robin"
temperature="0"
logprobs="TRUE"
top_logprobs="5"
num_prompts_in_batch="1"
limit="190000"
